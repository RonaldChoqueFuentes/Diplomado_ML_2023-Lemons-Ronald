{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "https://www.kaggle.com/datasets/yusufemir/lemon-quality-dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1701225226471
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import urllib\n",
        "from IPython.display import Image\n",
        "from zipfile import ZipFile\n",
        "from azure.ai.ml.entities import AmlCompute\n",
        "from azure.core.exceptions import ResourceNotFoundError\n",
        "\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml import automl\n",
        "from azure.identity import DefaultAzureCredential\n",
        "\n",
        "from azure.ai.ml.entities import Data\n",
        "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
        "from azure.ai.ml import Input\n",
        "\n",
        "from PIL import Image\n",
        "import jsonlines\n",
        "\n",
        "import json\n",
        "\n",
        "def get_azure_credential(subscription_id, resource_group, workspace):\n",
        "    credential = DefaultAzureCredential()\n",
        "    ml_client = MLClient.from_config(credential)\n",
        "    ml_client =  MLClient(credential, subscription_id, resource_group, workspace)\n",
        "    return ml_client\n",
        "\n",
        "ml_client = get_azure_credential(\"\",\"\",\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "and load zip file as \"Car-Bike-Dataset.zip\" under the project/data/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1701225277721
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "dataset_parent_dir = \"./data\"\n",
        "\n",
        "os.makedirs(dataset_parent_dir, exist_ok= True)\n",
        "dataset_name = \"lemon_Dataset\"\n",
        "dataset_dir = os.path.join(dataset_parent_dir, dataset_name)\n",
        "data_file = os.path.join(dataset_parent_dir, f\"{dataset_name}.zip\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1701225425727
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "extracting files...\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "with ZipFile(data_file, \"r\") as  zip:\n",
        "    print(\"extracting files...\")\n",
        "    zip.extractall(path=dataset_parent_dir)\n",
        "    print(\"done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Creando el data set de imagenes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1701225858660
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Your file exceeds 100 MB. If you experience low speeds, latency, or broken connections, we recommend using the AzCopyv10 tool for this file transfer.\n",
            "\n",
            "Example: azcopy copy '/mnt/batch/tasks/shared/LS_root/mounts/clusters/testnotebookrcf/code/Users/ron.todo.poderoso/Proyecto/data/lemon_Dataset' 'https://wsmlrcf4953324393.blob.core.windows.net/azureml-blobstore-7997d505-3695-4109-8af5-d01005f1102f/LocalUpload/e9dc3ece91713b64851c2c5c6247fe4a/lemon_Dataset' \n",
            "\n",
            "See https://docs.microsoft.com/azure/storage/common/storage-use-azcopy-v10 for more information.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'azureml://subscriptions/46169265-43c5-42f4-b171-b27bdd8e5afa/resourcegroups/rchoque/workspaces/ws_ml_rcf/datastores/workspaceblobstore/paths/LocalUpload/e9dc3ece91713b64851c2c5c6247fe4a/lemon_Dataset/'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def get_azure_data(name_data, images_directory):\n",
        "    my_data = Data(\n",
        "        path=images_directory,\n",
        "        type=AssetTypes.URI_FOLDER,\n",
        "        description=name_data,\n",
        "        name=name_data,\n",
        "        )\n",
        "    return my_data\n",
        "\n",
        "my_data = get_azure_data(\"lemon-items-images\", dataset_dir)\n",
        "uri_folder_data_asset = ml_client.data.create_or_update(my_data)\n",
        "uri_folder_data_asset.path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**create: lemon_objects.jsonl**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1701225988842
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "output_jsonl_file = \"lemon_objects.jsonl\"\n",
        "\n",
        "image_dir = \"./data/lemon_Dataset/\"\n",
        "\n",
        "blob_storage_objects_path=uri_folder_data_asset.path\n",
        "\n",
        "# List of classes\n",
        "classes = [\"bad_quality\", \"good_quality\", \"empty_background\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1701226085205
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images found in ./data/lemon_Dataset/bad_quality: 951\n",
            "images found in ./data/lemon_Dataset/good_quality: 1125\n",
            "images found in ./data/lemon_Dataset/empty_background: 452\n",
            "JSONL file 'lemon_objects.jsonl' has been created.\n"
          ]
        }
      ],
      "source": [
        "# Open the JSONL file for writing\n",
        "with jsonlines.open(output_jsonl_file, mode='w') as writer:\n",
        "    # Loop through each class directory\n",
        "    for class_name in classes:\n",
        "        class_dir = os.path.join(image_dir, class_name)\n",
        "        # Check if the class directory exists\n",
        "        if os.path.exists(class_dir) and os.path.isdir(class_dir):\n",
        "            # List all image files in the class directory\n",
        "            image_files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
        "            print(f'images found in {class_dir}: {len(image_files)}')\n",
        "            # Loop through each image file\n",
        "            for image_file in image_files:\n",
        "                # Construct the full image path\n",
        "                image_path = os.path.join(class_dir, image_file)\n",
        "                \n",
        "                # Open the image to get its details\n",
        "                with Image.open(image_path) as img:\n",
        "                    image_details = {\n",
        "                        \"format\": img.format,\n",
        "                        \"width\": img.width,\n",
        "                        \"height\": img.height\n",
        "                    }\n",
        "                img_path_names = image_path.split('/')\n",
        "                # Create the JSON object for this image\n",
        "                image_info = {\n",
        "                    \"image_url\": f\"{blob_storage_objects_path}{img_path_names[-2]}/{img_path_names[-1]}\",\n",
        "                    \"image_details\": image_details,\n",
        "                    \"label\": class_name\n",
        "                }\n",
        "                \n",
        "                # Write the JSON object to the JSONL file\n",
        "                writer.write(image_info)\n",
        "        else:\n",
        "            print(f'directory:{class_dir} does not exists')\n",
        "print(f\"JSONL file '{output_jsonl_file}' has been created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1701226103124
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'lemon_objects.jsonl'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "jsonl_annotations = output_jsonl_file\n",
        "jsonl_annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1701226136313
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "training_mltable_path = os.path.join(dataset_parent_dir, \"training-mltable-folder\")\n",
        "validation_mltable_path = os.path.join(dataset_parent_dir, \"validation-mltable-folder\")\n",
        "\n",
        "os.makedirs(training_mltable_path, exist_ok=True)\n",
        "os.makedirs(validation_mltable_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1701226147747
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_validation_ratio = 5\n",
        "training_annotations_file = os.path.join(training_mltable_path, \"training_annotations.jsonl\")\n",
        "validation_annotations_file = os.path.join(validation_mltable_path, \"validation_annotations.jsonl\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1701226160222
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "json_lines = None\n",
        "with open(jsonl_annotations, \"r\") as annot_f:\n",
        "    json_lines = annot_f.readlines()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1701226170485
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "index = 0\n",
        "\n",
        "with open(training_annotations_file, \"w\") as train_f:\n",
        "    with open(validation_annotations_file, \"w\") as validation_f:\n",
        "        for json_line in json_lines:\n",
        "            if index % train_validation_ratio == 0:\n",
        "                validation_f.write(json_line)\n",
        "            else:\n",
        "                train_f.write(json_line)\n",
        "            index+=1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "**Create a MLtable para enviar el job de AUTO ML**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1701226220465
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def create_ml_table_file(filename):\n",
        "    return (\n",
        "        \"paths:\\n\"\n",
        "        \"  - file: ./{0}\\n\"\n",
        "        \"transformations:\\n\"\n",
        "        \"  - read_json_lines:\\n\"\n",
        "        \"        encoding: utf8\\n\"\n",
        "        \"        invalid_lines: error\\n\"\n",
        "        \"        include_path_column: false\\n\"\n",
        "        \"  - convert_column_types:\\n\"\n",
        "        \"      - columns: image_url\\n\"\n",
        "        \"        column_type: stream_info\"\n",
        "    ).format(filename)\n",
        "\n",
        "def save_mltable_file(output_path, mltable_file_contents):\n",
        "    file_path = os.path.join(output_path, \"MLTable\")\n",
        "    with open(file_path, \"w\") as f:\n",
        "        f.write(mltable_file_contents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1701226237511
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "train_mltable_file_contents = create_ml_table_file(os.path.basename(training_annotations_file))\n",
        "save_mltable_file(training_mltable_path, train_mltable_file_contents)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1701226251298
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "validation_mltable_file_contents = create_ml_table_file(os.path.basename(validation_annotations_file))\n",
        "save_mltable_file(validation_mltable_path, validation_mltable_file_contents)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
